{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.chdir(\"/home/hamza-arain/Documents/code/recmmendation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8468, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "      <th>TotalPrice</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>536370</td>\n",
       "      <td>22728</td>\n",
       "      <td>ALARM CLOCK BAKELIKE PINK</td>\n",
       "      <td>24</td>\n",
       "      <td>2010-12-01 08:45:00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>12583.0</td>\n",
       "      <td>France</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2010-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>536370</td>\n",
       "      <td>22727</td>\n",
       "      <td>ALARM CLOCK BAKELIKE RED</td>\n",
       "      <td>24</td>\n",
       "      <td>2010-12-01 08:45:00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>12583.0</td>\n",
       "      <td>France</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2010-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InvoiceNo StockCode                Description  Quantity  \\\n",
       "26    536370     22728  ALARM CLOCK BAKELIKE PINK        24   \n",
       "27    536370     22727  ALARM CLOCK BAKELIKE RED         24   \n",
       "\n",
       "           InvoiceDate  UnitPrice  CustomerID Country  TotalPrice        Date  \n",
       "26 2010-12-01 08:45:00       3.75     12583.0  France        90.0  2010-12-01  \n",
       "27 2010-12-01 08:45:00       3.75     12583.0  France        90.0  2010-12-01  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/online_retail_final.csv\")\n",
    "\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "df['Date'] = df['InvoiceDate'].dt.date\n",
    "df = df[df['Country'] == \"France\"]\n",
    "\n",
    "\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Association Rule\n",
    "\n",
    "import joblib\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "class AssociationRule:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe.copy()\n",
    "        self.rules_path = \"output/rules.joblib\"\n",
    "        \n",
    "        # Check if the rules file exists\n",
    "        if os.path.exists(self.rules_path):\n",
    "            self.rules = joblib.load(self.rules_path)\n",
    "        else:\n",
    "            self.rules = self.train_rules(min_support=0.07, min_threshold=0.01)\n",
    "\n",
    "    def outlier_thresholds(self, dataframe, variable):\n",
    "        quartile1 = dataframe[variable].quantile(0.01)\n",
    "        quartile3 = dataframe[variable].quantile(0.99)\n",
    "        interquantile_range = quartile3 - quartile1\n",
    "        up_limit = quartile3 + 1.5 * interquantile_range\n",
    "        low_limit = quartile3 - 1.5 * interquantile_range\n",
    "        return low_limit, up_limit\n",
    "\n",
    "    def replace_with_thresholds(self, dataframe, variable):\n",
    "        low_limit, up_limit = self.outlier_thresholds(dataframe, variable)\n",
    "        dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "        dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n",
    "\n",
    "    def create_invoice_product_df(self, dataframe, id=False):\n",
    "        if id:\n",
    "            return dataframe.groupby(['InvoiceNo', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n",
    "                applymap(lambda x: 1 if x > 0 else 0)\n",
    "        else:\n",
    "            return dataframe.groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n",
    "                applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "    def preprocessing(self, dataframe):\n",
    "        dataframe.dropna(inplace=True)\n",
    "        dataframe = dataframe[~dataframe['InvoiceNo'].str.contains(\"C\", na=False)]\n",
    "        dataframe = dataframe[~dataframe['StockCode'].str.contains(\"POST\", na=False)]\n",
    "        dataframe = dataframe[~dataframe['StockCode'].str.contains(\"C2\", na=False)]\n",
    "        dataframe = dataframe[~dataframe['StockCode'].str.contains(\"M\", na=False)]\n",
    "\n",
    "        dataframe = dataframe[dataframe['Quantity'] > 0]\n",
    "        dataframe = dataframe[dataframe['UnitPrice'] > 0]\n",
    "        self.replace_with_thresholds(dataframe, \"Quantity\")\n",
    "        self.replace_with_thresholds(dataframe, \"UnitPrice\")\n",
    "        return dataframe\n",
    "\n",
    "    def encode_units(self, x):\n",
    "        if x <= 0:\n",
    "            return 0\n",
    "        if x >= 1:\n",
    "            return 1\n",
    "\n",
    "    def train_rules(self, min_support=0.07, min_threshold=0.01):\n",
    "        frequency_df = self.dataframe.copy()\n",
    "        frequency_df = self.preprocessing(frequency_df)\n",
    "\n",
    "        basket_df = self.create_invoice_product_df(frequency_df, id=True)\n",
    "        basket_df = basket_df.applymap(self.encode_units)\n",
    "\n",
    "        frequent_itemsets = apriori(basket_df, min_support=min_support, use_colnames=True)\n",
    "        rules = association_rules(frequent_itemsets,\n",
    "                                metric=\"lift\",\n",
    "                                min_threshold=min_threshold,\n",
    "                                num_itemsets=len(frequent_itemsets))\n",
    "        rules = rules.sort_values(\"lift\", ascending=False)\n",
    "\n",
    "        joblib.dump(rules , self.rules_path)\n",
    "        return rules\n",
    "\n",
    "    def recommend(self, product_id, support=0.05, confidence=0.1, lift=5):\n",
    "        sorted_rules = self.rules[(self.rules[\"support\"]>=support) & (self.rules[\"confidence\"]>=confidence) & (self.rules[\"lift\"]>lift)].sort_values(\"confidence\", ascending=False)\n",
    "\n",
    "        recommendation_list = []\n",
    "        for i, product in enumerate(sorted_rules[\"antecedents\"]):\n",
    "            for j in list(product):\n",
    "                if j == product_id:\n",
    "                    recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"])[0])\n",
    "        return list(set(recommendation_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeEngine:\n",
    "    def __init__(self, dataframe,\n",
    "                    user_matrix_path=\"output/user_collaborative_matrix.joblib\",\n",
    "                    co_occurrence_matrix_path=\"output/co_occurrence_matrix.joblib\"):\n",
    "        self.dataframe = dataframe.copy()\n",
    "\n",
    "        self.user_matrix_path = user_matrix_path\n",
    "        self.co_occurrence_matrix_path = co_occurrence_matrix_path\n",
    "\n",
    "        # Check if the rules file exists\n",
    "        if os.path.exists(self.user_matrix_path) and (os.path.exists(self.co_occurrence_matrix_path)):\n",
    "            self.user_matrix, self.co_occurrence_matrix = joblib.load(self.user_matrix_path), joblib.load(self.co_occurrence_matrix_path)\n",
    "        else:\n",
    "            self.user_matrix, self.co_occurrence_matrix = self.train_user_matrix()\n",
    "\n",
    "    def train_user_matrix(self):\n",
    "        # User Matrix\n",
    "        user_item_matrix = self.dataframe.pivot_table(index='CustomerID', columns='StockCode', values='Quantity', fill_value=0)\n",
    "\n",
    "        # Item based\n",
    "        # Create a time-aware co-occurrence matrix by considering only recent data\n",
    "        recent_data = self.dataframe[self.dataframe['InvoiceDate'] >= (self.dataframe['InvoiceDate'].max() - pd.Timedelta(days=30))]\n",
    "        co_occurrence_matrix = self.dataframe.pivot_table(index='StockCode', columns='CustomerID', values='Quantity', fill_value=0).T.dot(self.dataframe.pivot_table(index='StockCode', columns='CustomerID', values='Quantity', fill_value=0))\n",
    "        \n",
    "        joblib.dump(user_item_matrix, self.user_matrix_path) \n",
    "        joblib.dump(co_occurrence_matrix, self.co_occurrence_matrix_path)   \n",
    "  \n",
    "        return user_item_matrix, co_occurrence_matrix\n",
    "\n",
    "    def apply_time_decay(self, timestamp, current_time, decay_factor=0.8):\n",
    "        \"\"\"\n",
    "        Apply exponential time decay. Recent purchases are given higher weight.\n",
    "        \"\"\"\n",
    "        delta_days = (current_time - timestamp).days\n",
    "        decay_weight = np.exp(-decay_factor * delta_days)\n",
    "        return decay_weight\n",
    "\n",
    "    def user_based_recommendation(self, user, current_time, top_n=5, time_decay=0):\n",
    "        \"\"\"\n",
    "        User-based collaborative filtering recommendations with time decay.\n",
    "        \"\"\"\n",
    "        if user not in self.user_matrix.index:\n",
    "            return []  # Cold start user\n",
    "        \n",
    "        user_vector = self.user_matrix.loc[user].values.reshape(1, -1)\n",
    "        similarities = cosine_similarity(user_vector, self.user_matrix)[0]\n",
    "        \n",
    "        # Apply time decay to user interactions (recent purchases have higher weight)\n",
    "        time_weights = np.array([self.apply_time_decay(self.dataframe[self.dataframe['CustomerID'] == user]['InvoiceDate'].max(), current_time) \n",
    "                                for _ in range(len(similarities))])\n",
    "        similarities = similarities * time_weights  # Adjust similarity by time decay\n",
    "        \n",
    "        similar_users = self.user_matrix.index[np.argsort(-similarities)[1:top_n+1]]\n",
    "        recommended_items = self.user_matrix.loc[similar_users].sum().sort_values(ascending=False).index\n",
    "        return list(recommended_items[:top_n])\n",
    "\n",
    "    def item_based_recommendation(self, item, top_n=5):\n",
    "        \"\"\"\n",
    "        Item-based collaborative filtering using time-sensitive co-occurrence matrix.\n",
    "        \"\"\"\n",
    "        # Create a time-aware co-occurrence matrix by considering only recent data\n",
    "        recent_data = self.dataframe[self.dataframe['InvoiceDate'] >= (self.dataframe['InvoiceDate'].max() - pd.Timedelta(days=30))]\n",
    "        co_occurrence_matrix = self.dataframe.pivot_table(index='StockCode', columns='CustomerID', values='Quantity', fill_value=0).T.dot(self.dataframe.pivot_table(index='StockCode', columns='CustomerID', values='Quantity', fill_value=0))\n",
    "        \n",
    "        item_idx = co_occurrence_matrix.index.get_loc(item) if item in co_occurrence_matrix.index else None\n",
    "        \n",
    "        if item_idx is None:\n",
    "            return []  # If item is not in the matrix\n",
    "        \n",
    "        similar_items = co_occurrence_matrix.iloc[item_idx].sort_values(ascending=False).index[1:top_n+1]\n",
    "        return list(similar_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "class ContentBasedRecommedationSystem:\n",
    "    def __init__(self, dataframe, model_name='all-MiniLM-L6-v2', embeds_path=\"output/content_embeddings.joblib\", description_path=\"output/content_descriptions.joblib\"):\n",
    "        self.model = self.load_model(model_name)\n",
    "        self.dataframe = dataframe.copy()\n",
    "\n",
    "        self.embeds_path = embeds_path    \n",
    "        self.description_path = description_path\n",
    "        if os.path.exists(self.embeds_path) and os.path.exists(self.description_path):\n",
    "            self.descriptions, self.embeds = joblib.load(self.description_path), joblib.load(self.embeds_path) \n",
    "        else:\n",
    "            self.descriptions, self.embeds = self.train_embeddings()\n",
    "\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        embedding_model = SentenceTransformer(model_name)  \n",
    "        return embedding_model\n",
    "\n",
    "    def train_embeddings(self):\n",
    "        descriptions = self.dataframe.drop_duplicates('StockCode').set_index('StockCode')['Description'].fillna(\"\")\n",
    "        description_texts = descriptions.tolist()\n",
    "        embeddings = self.model .encode(description_texts, convert_to_tensor=True)\n",
    "        \n",
    "        joblib.dump(embeddings, self.embeds_path)\n",
    "        joblib.dump(descriptions, self.description_path)\n",
    "        return descriptions, embeddings\n",
    "\n",
    "    def recommend(self, item, top_n):\n",
    "        item_index = self.descriptions.index.get_loc(item) if item in self.descriptions.index else None\n",
    "        if item_index is None:\n",
    "            return []  # If item description is missing\n",
    "\n",
    "        # Get the embedding for the target item\n",
    "        item_embedding = self.embeds[item_index]\n",
    "        \n",
    "\n",
    "        # Compute cosine similarities\n",
    "        similarities = cosine_similarity([item_embedding], self.embeds)[0]\n",
    "\n",
    "        # Get the indices of the top N most similar items\n",
    "        top_indices = np.argsort(-similarities)[1:top_n + 1]\n",
    "        similar_items = self.descriptions.index[top_indices]\n",
    "        return list(similar_items)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridRecommendationSystem:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe.copy()\n",
    "        \n",
    "        ## Association Rule \n",
    "        self.association_rule = AssociationRule(dataframe=dataframe)\n",
    "\n",
    "        ## CollaborativeEngine for (user/item)\n",
    "        self.collaborative_engine = CollaborativeEngine(dataframe=dataframe)\n",
    "\n",
    "        ## Content based Recommendation\n",
    "        self.content_based_recommendation = ContentBasedRecommedationSystem(dataframe=dataframe)\n",
    "\n",
    "    def check_id(self, stock_code):\n",
    "        product_name = self.dataframe[self.dataframe[\"StockCode\"] == stock_code][[\"Description\"]].values[0].tolist()\n",
    "        return product_name[0]\n",
    "\n",
    "    def update_weights(self):\n",
    "        ## Association Rule \n",
    "        self.association_rule.train_rules(min_support=0.07, min_threshold=0.01)\n",
    "        \n",
    "        ## CollaborativeEngine for (user/item)\n",
    "        self.collaborative_engine.train_user_matrix()\n",
    "\n",
    "        ## Content based Recommendation\n",
    "        self.content_based_recommendation.train_embeddings()\n",
    "\n",
    "    def calculate_item_boost(self, item, recent_days=30):\n",
    "        \"\"\"\n",
    "        Boost score for items with low purchase frequency in recent time.\n",
    "        \"\"\"\n",
    "        recent_data = self.dataframe[self.dataframe['InvoiceDate'] >= (self.dataframe['InvoiceDate'].max() - pd.Timedelta(days=recent_days))]\n",
    "        item_purchases = recent_data['StockCode'].value_counts()\n",
    "        total_purchases = len(recent_data)\n",
    "        boost = (total_purchases - item_purchases.get(item, 0)) / total_purchases\n",
    "        return boost\n",
    "\n",
    "    def recommend(self, user, item, current_time, top_n=5):\n",
    "        # Define base weights for each methodrecommendations\n",
    "        base_weights = {\n",
    "            \"apriori\": 0.4,\n",
    "            \"user\": 0.3,\n",
    "            \"content\": 0.2,\n",
    "            \"item\": 0.1\n",
    "        }\n",
    "\n",
    "        # Check if the user is new\n",
    "        is_new_user = user not in self.collaborative_engine.user_matrix.index\n",
    "\n",
    "        # Adjust weights dynamically\n",
    "        if is_new_user:\n",
    "            base_weights['content'] += 0.2  # Favor content for new users\n",
    "            base_weights['item'] += 0.1  # Favor content for new users\n",
    "            base_weights['user'] = 0.0     # Ignore user-based recommendations for new users\n",
    "\n",
    "        # Get recommendations from each method\n",
    "        apriori_based = self.association_rule.recommend(item)\n",
    "        user_based = [] if is_new_user else  self.collaborative_engine.user_based_recommendation(user, current_time, top_n=top_n*2,time_decay=0)\n",
    "        item_based = self.collaborative_engine.item_based_recommendation(item, top_n * 2)\n",
    "        content_based = self.content_based_recommendation.recommend(item, top_n)\n",
    "\n",
    "        # Combine recommendations with weighted scores\n",
    "        scores = {}\n",
    "        for rank, recommendation in enumerate(apriori_based, start=1):\n",
    "            scores[recommendation] = scores.get(recommendation, 0) + base_weights['apriori'] / rank\n",
    "        for rank, recommendation in enumerate(user_based, start=1):\n",
    "            scores[recommendation] = scores.get(recommendation, 0) + base_weights['user'] / rank\n",
    "        for rank, recommendation in enumerate(content_based, start=1):\n",
    "            scores[recommendation] = scores.get(recommendation, 0) + base_weights['content'] / rank\n",
    "        for rank, recommendation in enumerate(item_based, start=1):\n",
    "            scores[recommendation] = scores.get(recommendation, 0) + base_weights['item'] / rank\n",
    "\n",
    "\n",
    "        # Apply boost for less frequent items in recent data\n",
    "        for recommendation in scores.keys():\n",
    "            scores[recommendation] += self.calculate_item_boost(recommendation)\n",
    "\n",
    "        # Sort items by their final weighted scores\n",
    "        sorted_recommendations = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Return the top_n recommendations\n",
    "        return [item[0] for item in sorted_recommendations[:top_n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Item: WHITE HANGING HEART T-LIGHT HOLDER\n",
      "\n",
      "Recommended Item: RED HANGING HEART T-LIGHT HOLDER\n",
      "Recommended Item: HANGING HEART ZINC T-LIGHT HOLDER\n",
      "Recommended Item: HANGING HEART JAR T-LIGHT HOLDER\n",
      "Recommended Item: T-LIGHT HOLDER HANGING LOVE BIRD\n",
      "Recommended Item: HANGING  BUTTERFLY T-LIGHT HOLDER\n"
     ]
    }
   ],
   "source": [
    "hbs = HybridRecommendationSystem(dataframe=df)\n",
    "# hbs.update_weights()\n",
    "\n",
    "# Example Usage\n",
    "user_id = 12345  # Replace with actual user\n",
    "item_code = '85123A'  # Replace with actual item\n",
    "current_time = pd.to_datetime(\"2024-12-01\")  # Current date (for time-decay)\n",
    "\n",
    "\n",
    "recommendations = hbs.recommend(user_id, item_code, current_time, top_n=5)\n",
    "\n",
    "print(f\"Selected Item: {hbs.check_id(item_code)}\")\n",
    "\n",
    "print()\n",
    "\n",
    "for recomended in recommendations:\n",
    "    print(f\"Recommended Item: {hbs.check_id(recomended)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
